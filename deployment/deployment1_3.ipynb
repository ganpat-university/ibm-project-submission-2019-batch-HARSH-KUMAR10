{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjL6m9HUxNYI",
        "outputId": "2faa4d72-2c28-4f6f-ec09-dfcb3517b262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "my name is harsh => કોઈનેય\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "how are you => મનની ચંદ્રાયાન એમએમયુ\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "how is this => ટ્રેનના ઓક્ટોબરને ધર્યા\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import tokenizer_from_json\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Load the saved tokenizers and models\n",
        "# Load tokenizer from JSON file\n",
        "with open('/content/drive/MyDrive/Sem_8-G21/model/input_tokenizer.json', 'r') as f:\n",
        "    input_tokenizer = tokenizer_from_json(json.dumps(json.load(f)))\n",
        "\n",
        "# Similarly, load the Gujarati tokenizer\n",
        "with open('/content/drive/MyDrive/Sem_8-G21/model/output_tokenizer.json', 'r') as f:\n",
        "    output_tokenizer = tokenizer_from_json(json.dumps(json.load(f)))\n",
        "\n",
        "    \n",
        "normal_model = tf.keras.models.load_model('/content/drive/MyDrive/Sem_8-G21/model/eng-to-gujarati.h5')\n",
        "encoder_model = tf.keras.models.load_model('/content/drive/MyDrive/Sem_8-G21/model/Encoder-Model.h5')\n",
        "decoder_model = tf.keras.models.load_model('/content/drive/MyDrive/Sem_8-G21/model/Decoder-Model.h5')\n",
        "\n",
        "normal_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "encoder_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "decoder_model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "def decode_sequence(input_sentence):\n",
        "    # Encode the input as state vectors.\n",
        "    enc_output, enc_hidden = encoder_model.predict(input_tokenizer.texts_to_sequences([input_sentence]))\n",
        "\n",
        "    # Generate an empty target sequence of length 1.\n",
        "    target_sequence = np.zeros((1, 1))\n",
        "\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_sequence[0, 0] = output_tokenizer.word_index['start']\n",
        "\n",
        "    # Initialize the decoder state with the encoder hidden state.\n",
        "    dec_hidden = enc_hidden\n",
        "    stop_condition = False\n",
        "    guj_sentence = ''\n",
        "    \n",
        "    while not stop_condition:\n",
        "        dec_output, dec_hidden, attention_weights = decoder_model.predict([target_sequence, dec_hidden, enc_output])\n",
        "\n",
        "        # Sample a token from the output distribution\n",
        "        sampled_token_index = np.argmax(dec_output[0, -1, :])\n",
        "        \n",
        "        if sampled_token_index not in output_tokenizer.index_word:\n",
        "            break\n",
        "            \n",
        "        sampled_token = output_tokenizer.index_word[sampled_token_index]\n",
        "\n",
        "        # Append the sampled token to the target sequence\n",
        "        guj_sentence += ' ' + sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop character.\n",
        "        if (sampled_token == 'end' or len(guj_sentence) > 20):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_sequence = np.zeros((1, 1))\n",
        "        target_sequence[0, 0] = sampled_token_index\n",
        "\n",
        "    return guj_sentence.strip()\n",
        "\n",
        "\n",
        "# Test the model with some example sentences\n",
        "input_sentence = 'my name is harsh'\n",
        "guj_sentence = decode_sequence(input_sentence)\n",
        "print(input_sentence + ' => ' + guj_sentence)\n",
        "\n",
        "input_sentence = 'how are you'\n",
        "guj_sentence = decode_sequence(input_sentence)\n",
        "print(input_sentence + ' => ' + guj_sentence)\n",
        "\n",
        "input_sentence = 'how is this'\n",
        "guj_sentence = decode_sequence(input_sentence)\n",
        "print(input_sentence + ' => ' + guj_sentence)\n",
        "\n",
        "# # Save the model as a TensorFlow SavedModel\n",
        "# tf.saved_model.save(normal_model, 'normal_model_saved_model')\n",
        "# tf.saved_model.save(encoder_model, 'encode_model_saved_model')\n",
        "# tf.saved_model.save(decoder_model, 'decode_model_saved_model')\n"
      ]
    }
  ]
}